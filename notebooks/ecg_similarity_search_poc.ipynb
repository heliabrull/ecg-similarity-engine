{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proof-of-concept: ECG similarity search engine\n",
    "\n",
    "This Jupyter notebook presents a proof-of-concept system for retrieving ECGs based on similarity across multiple ML-derived metrics. It includes:\n",
    "\n",
    "1. Synthetic data generation with clinically meaningful structure\n",
    "\n",
    "2. Feature preprocessing \n",
    "\n",
    "3. Feature indexing using FAISS\n",
    "\n",
    "4. A flexible querying mechanism supporting feature selection and weighting, with illustrative query examples\n",
    "\n",
    "\n",
    "The notebook complements the accompanying report by demonstrating the core implementation and validating the system’s performance under realistic conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start by importing the needed packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from src.data_generator import DataGenerator\n",
    "from src.data_preprocessor import DataPreprocessor\n",
    "from src.similarity_searcher import SimilaritySearcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Synthetic data generation\n",
    "\n",
    "We will use `DataGenerator` to simulate a synthetic dataset of ECGs of dimension N. For this example, we will pick N = 100,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100000\n",
    "generator = DataGenerator(num_ecgs=N)\n",
    "data = generator.generate_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Feature preprocessing\n",
    "\n",
    "Next, we will use `DataPreprocessor` to apply the corresponding pre-processing techniques to each feature groups, namely:\n",
    "\n",
    "- Heart rate: Standardized (mean 0, std 1).\n",
    "\n",
    "- Risk scores: Each of the 5 condition scores is standardized independently.\n",
    "\n",
    "- Embeddings: Standardized and reduced with PCA for compactness.\n",
    "\n",
    "- Beat-type proportions: Used as-is (already normalized between 0 and 1).\n",
    "\n",
    "This produces a unified matrix of preprocessed vectors, ready for indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = DataPreprocessor()\n",
    "processed_data = preprocessor.fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Feature indexing \n",
    "\n",
    "We use the `SimilaritySearcher` class to build and manage two types of FAISS indexes:\n",
    "\n",
    "- Single Index (orchestrated by `SingleIndexer` class): Builds the index over the entire feature vector for full-vector similarity search.\n",
    "\n",
    "- Hybrid Index (orchestrated by `HybridIndexer` class): Builds separate FAISS indexes for each feature group (e.g., heart rate, risk scores, embeddings), supporting modular and interpretable queries.\n",
    "\n",
    "Index construction is done in batches for scalability and memory efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the size of the dataset, we will implement `IndexHNSWFlat` (approximate search) for all the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SingleIndex: building index with type <hnsw>: 100%|██████████| 1/1 [00:01<00:00,  1.38s/it]\n",
      "HybridIndexer: building for group <heart_rate> with index type <hnsw>: 100%|██████████| 1/1 [00:00<00:00,  1.29it/s]\n",
      "HybridIndexer: building for group <risk_scores> with index type <hnsw>: 100%|██████████| 1/1 [00:01<00:00,  1.19s/it]\n",
      "HybridIndexer: building for group <embedding> with index type <hnsw>: 100%|██████████| 1/1 [00:01<00:00,  1.17s/it]\n",
      "HybridIndexer: building for group <beat_props> with index type <hnsw>: 100%|██████████| 1/1 [00:01<00:00,  1.15s/it]\n"
     ]
    }
   ],
   "source": [
    "hnsw_index_config = {\n",
    "    \"heart_rate\": \"hnsw\",\n",
    "    \"risk_scores\": \"hnsw\",\n",
    "    \"embedding\": \"hnsw\",\n",
    "    \"beat_props\": \"hnsw\",\n",
    "}\n",
    "searcher = SimilaritySearcher(\n",
    "    full_matrix=processed_data,\n",
    "    group_shapes=preprocessor.group_shapes,\n",
    "    group_index_types=hnsw_index_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Querying\n",
    "\n",
    "We use the SimilaritySearcher to perform similarity queries on the indexed ECG feature vectors.\n",
    "\n",
    "- Users can specify which feature groups to consider in the similarity computation (e.g., [\"embedding\", \"heart_rate\"]).\n",
    "\n",
    "- Each group can be assigned a custom weight, allowing fine-grained control over the influence of different features.\n",
    "\n",
    "- If all feature groups are selected, the system uses the full-vector index for fast retrieval.\n",
    "\n",
    "- Otherwise, it uses the hybrid index, combining results from selected groups using normalized distances and weighted scoring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before querying, we must preprocess the input ECG vector using the same transformations applied during indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's assume we want to search for the nearest neighbors of a specific ECG record by its ID (and we know it exists)\n",
    "query_id = \"ecg_99999\"\n",
    "\n",
    "# Extract the query vector for the specified ID and preprocess it\n",
    "query_idx = data.index.get_loc(query_id)\n",
    "query_vector = data.loc[[query_id]]\n",
    "query_processed = preprocessor.transform(query_vector)\n",
    "\n",
    "# Extract the cluster for the query vector\n",
    "query_cluster = query_vector[\"cluster\"].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's define a simple function to run the similarity search on different feature groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_similarity_query(\n",
    "    searcher,\n",
    "    query_processed,\n",
    "    query_idx,\n",
    "    query_cluster,\n",
    "    top_k=100,\n",
    "    selected_groups=None,\n",
    "    database_size=None,\n",
    "    df=data,\n",
    "):\n",
    "    \"\"\"\n",
    "    Run a similarity query and report key stats.\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "        searcher: SimilaritySearcher instance.\n",
    "        query_processed: Preprocessed query vector (1xD).\n",
    "        query_idx: Index of the query in the database (used to exclude from results).\n",
    "        query_cluster: Cluster label of the query ECG.\n",
    "        top_k: Number of neighbors to retrieve (default = 100).\n",
    "        selected_groups: Feature groups to query over.\n",
    "        database_size: Optional, for logging database size.\n",
    "        df: DataFrame containing metadata (e.g., clusters).\n",
    "    \"\"\"\n",
    "\n",
    "    # Perform the search\n",
    "    start_time = time.time()\n",
    "    indices, distances = searcher.search(\n",
    "        query_processed,\n",
    "        top_k=top_k + 1,  # fetch extra to allow removing the query itself\n",
    "        selected_groups=selected_groups,\n",
    "    )\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    # Post-process results to remove the query itself\n",
    "    indices = np.asarray(indices).flatten()\n",
    "    distances = np.asarray(distances).flatten()\n",
    "\n",
    "    if query_idx in indices:\n",
    "        mask = indices != query_idx\n",
    "        indices = indices[mask]\n",
    "        distances = distances[mask]\n",
    "\n",
    "    # Trim to top-k\n",
    "    top_k_actual = min(top_k, len(indices))\n",
    "    indices = indices[:top_k_actual]\n",
    "    distances = distances[:top_k_actual]\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Query by group(s): {selected_groups}\")\n",
    "    print(f\"Number of ECGs in database: {database_size or len(df)}\")\n",
    "    print(f\"Top-k retrieved: {top_k_actual}\")\n",
    "    print(f\"Query time: {elapsed_time:.4f} seconds\")\n",
    "\n",
    "    # Print cluster distribution of the retrieved ECGs\n",
    "    cluster_counts = df.iloc[indices][\"cluster\"].value_counts(normalize=True)\n",
    "    print(f\"\\nQuery ECG cluster: {query_cluster}\")\n",
    "    print(\"Cluster distribution among retrieved ECGs:\")\n",
    "    print(cluster_counts.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Experiment 1: Heart rate only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query by group(s): ['heart_rate']\n",
      "Number of ECGs in database: 100000\n",
      "Top-k retrieved: 100\n",
      "Query time: 0.0005 seconds\n",
      "\n",
      "Query ECG cluster: pvc_heavy\n",
      "Cluster distribution among retrieved ECGs:\n",
      "cluster\n",
      "normal        0.72\n",
      "pvc_heavy     0.13\n",
      "ischemia      0.12\n",
      "afib_prone    0.03\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "run_similarity_query(\n",
    "    searcher,\n",
    "    query_processed,\n",
    "    query_idx,\n",
    "    query_cluster,\n",
    "    top_k=100,\n",
    "    selected_groups=[\"heart_rate\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis**: We're using only `heart_rate` for similarity search, which triggers the use of `HybridIndex` with index `IndexHNSWFlat`. Since only one feature group is selected, the system executes a single top-k search without applying margin expansion, normalization, or score aggregation.. The system retrieves mainly examples for clusters that have a similar heart rate by design (e.g. \"normal\" and \"ischemia\" clusters), with the proportions specified in the cluster distribution (e.g. \"normal\" being the majority cluster). The query time is well below the limit of 1s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example 2: Heart rate and  beat type proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query by group(s): ['heart_rate', 'beat_props']\n",
      "Number of ECGs in database: 100000\n",
      "Top-k retrieved: 100\n",
      "Query time: 0.0100 seconds\n",
      "\n",
      "Query ECG cluster: pvc_heavy\n",
      "Cluster distribution among retrieved ECGs:\n",
      "cluster\n",
      "normal        0.52\n",
      "pvc_heavy     0.37\n",
      "ischemia      0.09\n",
      "afib_prone    0.02\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "run_similarity_query(\n",
    "    searcher,\n",
    "    query_processed,\n",
    "    query_idx,\n",
    "    query_cluster,\n",
    "    top_k=100,\n",
    "    selected_groups=[\"heart_rate\", \"beat_props\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis**: We're now including the feature `beat_props`. The system starts retrieving a higher proportion of examples within the cluster of the queried ECG. Because more than one feature group is selected, the system retrieves now `top_k × margin_factor` candidates from each group, followed by normalization and score aggregation. This introduces a slight increase in query time due to the additional index lookup, margin expansion and post-processing, but it remains well below the 1-second threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example 3: Heart rate, beat type proportions and risk of AFib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query by group(s): ['heart_rate', 'beat_props', 'risk_afib']\n",
      "Number of ECGs in database: 100000\n",
      "Top-k retrieved: 100\n",
      "Query time: 0.0857 seconds\n",
      "\n",
      "Query ECG cluster: pvc_heavy\n",
      "Cluster distribution among retrieved ECGs:\n",
      "cluster\n",
      "pvc_heavy     0.50\n",
      "normal        0.42\n",
      "ischemia      0.06\n",
      "afib_prone    0.02\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "run_similarity_query(\n",
    "    searcher,\n",
    "    query_processed,\n",
    "    query_idx,\n",
    "    query_cluster,\n",
    "    top_k=100,\n",
    "    selected_groups=[\"heart_rate\", \"beat_props\", \"risk_afib\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis**: When including another feature group, `risk_afib`, the proportion of samples within the cluster of the query vector further increases. Note that we queried on `risk_afib` but that the system used the combined index `risk_scores`, meaning we would have the same results no matter what risk score we queried on. The query time increased because of the addition of a feature but is still well below the limit of 1s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query by group(s): None\n",
      "Number of ECGs in database: 100000\n",
      "Top-k retrieved: 100\n",
      "Query time: 0.0003 seconds\n",
      "\n",
      "Query ECG cluster: pvc_heavy\n",
      "Cluster distribution among retrieved ECGs:\n",
      "cluster\n",
      "pvc_heavy    1.0\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "run_similarity_query(searcher, query_processed, query_idx, query_cluster, top_k=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis**: In this example we're not specifying any selected groups, so the similarity search is done with `SingleIndexer`on the index built with all the features. This reduces the search time dramatically, as there is a single search with `HNSW`. In terms of cluster distribution amongst the retrieves examples, we can see all of them belong to the cluster of the queried ECG."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
